# Проектирование расширенных подсказок (Advanced prompt engineering)

[![Создание расширенных подсказок](./images/05-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://learn.microsoft.com/_themes/docs.theme/master/en-us/_themes/global/video-embed.html?id=f3615e46-dbca-477c-832d-21eef95cd9f3?WT.mc_id=academic-105485-koreyst)

Давайте подведем некоторые итоги из предыдущей главы:

> Prompt _engineering_  — это процесс, с помощью которого мы **направляем модель к более релевантным ответам**, предоставляя более полезные инструкции или контекст.

Есть также два этапа написания подсказки: создание подсказки путем предоставления соответствующего контекста, а вторая часть — это _оптимизация_, как постепенно улучшать подсказку.

На данный момент у нас есть некоторое базовое понимание того, как писать подсказки, но нам нужно пойти глубже. В этой главе вы пройдете путь от опробования различных подсказок к пониманию того, почему одна подсказка лучше другой. Вы узнаете, как создавать подсказки, используя некоторые базовые методы, которые можно применить к любому LLM.

## Введение

В этой главе мы рассмотрим следующие темы:

- Расшиение ваших знаний в области разработки подсказок, применение к подсказкам различных методов.
- Настройка подсказок для изменения вывода.

## Цели обучения

После завершения этого урока вы сможете:

- Применять методы оперативного проектирования, которые улучшат результаты ваших подсказок.
- Применять подсказки, которые могут быть разнообразными или детерминированными.

## Проектирование подсказок

Проектирование подсказок — это процесс создания подсказок, которые приведут к желаемому результату. Инженерные подсказки — это нечто большее, чем просто написание текстовой подсказки. Проектирование подсказок— это не инженерная дисциплина, а скорее набор методов, которые можно применить для получения желаемого результата.

### Пример подсказки

Давайте возьмем базовую подсказку вроде этой:

> Создай 10 вопросов по географии.

В этой подсказке вы фактически применяете набор различных методов подсказки.

Давайте разберем это.

- **Контекст**, вы указываете, речь должна идти о «географии».
- **Ограничение вывода**: вам нужно не более 10 вопросов.

### Ограничения простых подсказок

Вы можете получить или не получить желаемый результат. Вопросы, конечно, будут сгенерированы, но география — это большая тема, и вы можете получить не то, что хотите, по следующим причинам:

- **Довольно обширная тема**, вы не знаете, будет ли речь идти о странах, столицах, реках и так далее.
- **Формат**. Что, если вы хотите, чтобы вопросы были отформатированы определенным образом?

Как видите, при создании подсказок нужно учитывать множество факторов.

До сих пор мы видели лишь простые примеры, но генеративный ИИ способен на гораздо большее, помогая людям в самых разных ролях и отраслях. Далее давайте рассмотрим некоторые основные методы.

### Техники подсказок

Во-первых, нам необходимо понять, что подсказка — это новое свойство LLM, означающее, что это не функция, встроенная в модель, а скорее то, что мы обнаруживаем в процессе использования модели.

Есть несколько основных методов, которые мы можем использовать для получения ввода в LLM. Давайте изучим их.

Zero-shot prompting (Подсказка без обучения) - это самая базовая форма подсказок. Это сам запрос, требующий ответа от LLM, основываясь исключительно на его обучающих данных.

Few-shot prompting (Подсказка с небольшим количеством примеров) - этот тип подсказок направляет LLM, предоставляя один или несколько примеров, на которые он может опираться при формировании ответа.

Chain-of-thought (Цепочка мыслей) - этот тип подсказок указывает LLM, как разбить проблему на этапы.

Generated knowledge (Сгенерированные знания) - чтобы улучшить ответ на запрос, вы можете предоставить сгенерированные факты или знания в дополнение к вашей подсказке.

Least to most (От минимума к максимуму) - подобно цепочке мыслей, эта техника заключается в разбиении проблемы на серию шагов и последовательном их выполнении в порядке возрастания.

Self-refine (Самоусовершенствование) - эта техника заключается в критическом осмыслении вывода LLM и последующем его улучшении.

Maieutic prompting (Майевтическая подсказка) - здесь вы хотите убедиться, что ответ LLM является правильным, и просите его объяснить различные части ответа. Это форма самоусовершенствования.

### Zero-shot prompting (подсказка без обучения)

Этот стиль подсказки очень простой, он состоит из одной подсказки. Эта техника, вероятно, то, что вы используете, когда начинаете изучать языковые модели на основе больших данных. Вот пример:

Подсказка: "Что такое алгебра?"
Ответ: "Алгебра - это раздел математики, который изучает математические символы и правила их преобразования."

### Few-shot prompting (провокация с небольшим количеством примеров)

Этот стиль подсказки помогает модели, предоставляя несколько примеров вместе с запросом. Он состоит из одной подсказки с дополнительными данными, специфичными для задачи. Вот пример:

Подсказка: "Напишите стихотворение в стиле Шекспира. Вот несколько примеров Шекспировских сонетов:
Сонет 18: 'Пусть буду ль я сравнивать тебя с летним днем? Ты прекрасней и умеренней...'
Сонет 116: 'Не допущу я пусть встречи истинных душ преград. Любовь не любовь, если меняется при перемене...'
Сонет 132: 'Твои глаза, и я их люблю, они, сжалившись надо мной, Зная, как сердце мое страдает от твоего презрения,...'
Теперь напишите сонет о красоте луны."
Ответ: "На небе луна мягко светит, В серебристом свете, что ласкает своей нежностью,..."
Примеры предоставляют языковой модели контекст, формат или стиль желаемого вывода. Они помогают модели понять конкретную задачу и генерировать более точные и соответствующие ответы.

### Chain-of-thought (цепочка мыслей)

Цепочка мыслей (chain-of-thought) - это очень интересная техника, поскольку она заключается в проведении языковой модели через серию шагов. Идея заключается в том, чтобы инструктировать модель таким образом, чтобы она понимала, как выполнить определенное действие. Рассмотрим следующий пример с и без применения цепочки мыслей:

Подсказка: "У Алисы есть 5 яблок, она выбрасывает 3 яблока, отдает 2 яблока Бобу, и Боб возвращает одно яблоко, сколько яблок остается у Алисы?"
Ответ: 5
Языковая модель отвечает 5, что неверно. Правильный ответ - 1 яблоко, основываясь на расчете (5 - 3 - 2 + 1 = 1).

Как мы можем научить языковую модель делать это правильно?

Давайте попробуем использовать цепочку мыслей. Применение цепочки мыслей означает:

Дать языковой модели аналогичный пример.
Показать расчет и как правильно выполнить его.
Предоставить исходную подсказку.
Вот как это может выглядеть:

Подсказка: "У Лизы есть 7 яблок, она выбрасывает 1 яблоко, отдает 4 яблока Барту, и Барт возвращает одно яблоко:
7 - 1 = 6
6 - 4 = 2
2 + 1 = 3
У Алисы есть 5 яблок, она выбрасывает 3 яблока, отдает 2 яблока Бобу, и Боб возвращает одно яблоко, сколько яблок остается у Алисы?"
Ответ: 1
Обратите внимание, как мы создаем существенно более длинную подсказку с другим примером, расчетом и затем исходной подсказкой, и мы получаем правильный ответ - 1.

Как видите, цепочка мыслей является очень мощной техникой.

### Сгенерированные знания (generated knowlege)

Часто, когда вам нужно создать подсказку, вы хотите использовать данные вашей собственной компании. Вы хотите, чтобы часть подсказки была связана с компанией, а другая часть должна быть самой предполагаемой подсказкой, которая вас интересует.

В качестве примера, вот как может выглядеть ваша подсказка, если вы занимаетесь страховым бизнесом:

    ```text
    {{company}}: {{company_name}}
    {{products}}:
    {{products_list}}
    Пожалуйста, порекомендуйте страховку на основе следующего бюджета и требований:
    Бюджет: {{budget}}
    Требования: {{requirements}}
    ```

Выше вы видите, как подсказка создается с использованием шаблона. В шаблоне есть несколько переменных, обозначенных как {{переменная}}, которые будут заменены фактическими значениями из API компании.

Вот пример того, как может выглядеть подсказка после того, как переменные были заменены содержимым из вашей компании:

    ```text
    Страховая компания: ACME Insurance
    Страховые продукты (стоимость в месяц):
    - Автомобиль, недорогой, 500 долларов США
    - Автомобиль, дорогой, 1100 долларов США
    - Жилье, недорогое, 600 долларов США
    - Жилье, дорогое, 1200 долларов США
    - Жизнь, недорогая, 100 долларов США

    Пожалуйста, порекомендуйте страховку на основе следующего бюджета и требований:
    Бюджет: 1000 долларов США
    Требования: Автомобиль, Жилье
    ```

Запуск данной подсказки через LLM приведет к получению ответа вроде следующего:

    ```output
    , и страхование жизни
    Учитывая бюджет и требования, мы предлагаем следующий страховой пакет от ACME Insurance:
 - Автомобиль, дешевая, 500 долларов США
 - Дом, недорогая, 600 долларов США
 - Жизнь, дешевая, 100 долларов США
 Общая стоимость: 1200 долларов США.
    ```

Как видите, это также предполагает страхование жизни, чего не должно быть. Этот результат указывает на то, что нам необходимо оптимизировать подсказку, изменив ее, чтобы было более понятно, что она может разрешить. После некоторых проб и ошибок мы получаем следующее приглашение:

    ```текст
    Страховая компания: ACME Insurance
    Страховые продукты (стоимость в месяц):
    - тип: Легковой, недорогой, стоимость: 500 у.е.
    - тип: Автомобиль, дорогой, стоимость: 1100 у.е.
    - тип: Домашний, дешевый, стоимость: 600 у.е.
    - тип: Домашний, дорогой, стоимость: 1200 у.е.
    - тип: Жизнь, дешево, стоимость: 100 долларов США

    Пожалуйста, предложите страховку, учитывая следующий бюджет и требования:
    Бюджет: $1000. Ограничьте выбор типами: Автомобиль, Дом.
    ```

Обратите внимание, как добавление _type_ и _cost_, а также использование ключевого слова _restrict_ помогает LLM понять, чего мы хотим.
Now we get the following response:

    ```вывод
    Учитывая бюджет и требования, мы предлагаем страховой продукт «Автомобиль, Дешево», стоимость которого составляет 500 долларов США в месяц.
    ```

Цель этого примера заключалась в том, чтобы показать, что хотя мы и используем базовый метод, такой как _сгенерированные знания_, в большинстве случаев нам все равно необходимо оптимизировать подсказку, чтобы получить желаемый результат.

### От меньшего к большему (least-to-most)

Техника "От меньшего к большему" заключается в разбиении большой проблемы на подзадачи. Таким образом, вы помогаете направить LLM в решении более крупной проблемы. Хорошим примером может быть область науки о данных, где вы можете попросить LLM разделить проблему следующим образом:

> Подсказка: Как описать науку о данных в 5 шагах?

AI-помощник может ответить следующим образом:

1. Собрать данные - Этот шаг включает сбор соответствующих данных из различных источников, таких как базы данных, API или файлы.
2. Очистить данные - После сбора данных необходимо выполнить их предварительную обработку и очистку. Этот шаг включает обработку отсутствующих значений, работу с выбросами и обеспечение согласованности данных.
3. Анализировать данные - После очистки данных можно применить различные аналитические методы, такие как статистический анализ, алгоритмы машинного обучения или методы добычи данных, для получения информации и извлечения значимых результатов.
4. Визуализировать данные - Визуализация данных является важным этапом для понимания закономерностей и взаимосвязей. Этот шаг включает создание диаграмм, графиков или других визуальных представлений для эффективного передачи результатов.
5. Представить данные - Наконец, необходимо представить анализ и полученные результаты в ясной и лаконичной форме. Это может включать создание отчетов, информационных панелей или презентаций для передачи результатов заинтересованным сторонам или лицам, принимающим решения.

### Самосовершенствование, корректировка результатов (self-refine, critique the results)

С генеративными искусственными интеллектами и моделями на основе LLM нельзя полностью доверять результатам. Необходимо их проверять. В конце концов, LLM просто представляет вам наиболее вероятное следующее высказывание, а не обязательно правильное. Поэтому хорошей идеей является просить LLM оценить себя, что приводит нас к технике самоусовершенствования.

Как это работает: вы следуете следующим шагам:

1. Первоначальный запрос, в котором вы просите LLM решить проблему.
2. LLM дает ответ.
3. Вы критикуете ответ и просите искусственный интеллект улучшить его.
4. LLM отвечает снова, на этот раз учитывая критику и предлагая решения, которые он придумал.

Вы можете повторить этот процесс столько раз, сколько захотите.

Вот пример использования этой техники:

> Подсказка: Создай веб-API на Python с маршрутами "products" и "customers".

ИИ Ответ:

    ```python
    import flask
    app = Flask(__name__)

    @app.route('/products')
    def products():
        return 'Products'

    @app.route('/customers')
    def customers():
        return 'Customers'
    ```

> Подсказка: Предложи 3 улучшения для кода выше

ИИ Ответ:

    ```text
    Конечно, вот три предложения для улучшения кода:

    Импортируйте правильный модуль: Первая строка должна импортировать Flask, а не flask. Правильная инструкция импорта должна выглядеть так: from flask import Flask.

    Добавьте функцию main: Добавьте блок if __name__ == '__main__': в конце файла, чтобы при выполнении файла запускалось приложение.

    Используйте f-строки: Используйте f-строки для форматирования операторов return в функциях маршрутов. Например, return 'Products' можно заменить на return f'This is the {request.path} page'.
    ```

    ```python
    from flask import Flask, request

    app = Flask(__name__)

    @app.route('/products')
    def products():
        return f'This is the {request.path} page'

    @app.route('/customers')
    def customers():
        return f'This is the {request.path} page'

    if __name__ == '__main__':
        app.run()
    ```

Как видите, приведенный выше ответ ИИ улучшает первый предложенный код благодаря критике первого ответа.

### Майевтическое подсказывание (maieutic prompting)

Метод майевтического подсказывания (maieutic prompting) похож на самоусовершенствование (self-refine), но больше связан с просьбой к LLM объяснить свой ответ. Целью является устранение несогласованностей в выводе LLM, чтобы обеспечить правильный ответ. Рекомендуемая последовательность действий следующая:

1. Попросите LLM ответить на вопрос.
2. Для каждой части ответа попросите LLM дать более подробное объяснение.
3. Если есть несогласованности, отбросьте части ответа, которые являются несогласованными.

Повторяйте шаги 2 и 3, пока не пройдете все части и не будете удовлетворены ответом.

Вот пример подсказки:

> Подсказка: Как я могу создать кризисный план по смягчению последствий пандемии за 5 шагов?
> Ответ LLM:

    ```text
    1. Определить риски
    1. Определите заинтересованные стороны
    1. Определите ресурсы
    1. Определите действия
    1. Определите каналы связи
    ```

Определено 5 шагов, но можем ли мы определить, правильны ли они? Давайте попросим LLM объяснить каждый шаг:

> Подсказка: Объясните первый шаг более подробно, каковы могут быть риски?

    ```text
        Риски следующие:

        - Потеря жизни
        - Потеря бизнеса
        - Потеря репутации.
        - Потеря клиентов.
        - Потеря сотрудников
    ```

На данном этапе мы хотим убедиться, что LLM правильно поняла вопрос, поэтому мы просим ее подробнее объяснить первый риск и надеемся, что его ответ будет согласован с предыдущим ответом.

> Подсказка: Касаемо пандемии, каков самый большой риск и почему?

    ```text
    Самый большой риск – это гибель людей, потому что это самое важное, что нужно защитить.
    ```

> "Каковы два самых больших риска в пандемии?"

    ```text
    Двумя самыми большими рисками являются гибель людей и потеря бизнеса.
    ```

На этом этапе LLM последовательна и упоминает «жизнь» и «бизнес» как два главных риска. Теперь мы можем перейти к следующему шагу и чувствовать себя достаточно уверенно. Однако мы не должны слепо доверять LLM, мы всегда должны проверять вывод.

## Меняйте результат

LLM недетерминированы по своей природе, а это означает, что вы будете получать разные результаты каждый раз, когда вводите одно и то же. Попробуйте, например, следующую подсказку:

> "Сгенерируйте код для Python веб-API"

    ```text
    # Импорт необходимых модулей
    import flask
    from flask import request, jsonify

    # Создание a Flask app
    app = flask.Flask(__name__)

    # Создание маршрута для API
    @app.route('/api', methods=['GET'])
    def api():
        # Получение данных от запроса
        data = request.args

        # Обработка данных
        result = process_data(data)

        # Возвращение результат в виде JSON
        return jsonify(result)

    # Функция для обработки данных
    def process_data(data):
        # Активно обрабатываем данные
        result = data + 1

        # Возвращаем результат
        return result

    # Запуск приложения
    if __name__ == '__main__':
        app.run()

    ```

Повторный ввод того же приведет к немного другому ответу:

    ```text
    #Импорт пакетов
    import flask
    from flask import request, jsonify

    #Создание Flask приложения
    app = flask.Flask(__name__)
    app.config["DEBUG"] = True

    #Создание списка книг
    books = [
        {'id': 0,
         'title': 'A Fire Upon the Deep',
         'author': 'Vernor Vinge',
         'first_sentence': 'The coldsleep itself was dreamless.',
         'year_published': '1992'},
        {'id': 1,
         'title': 'The Ones Who Walk Away From Omelas',
         'author': 'Ursula K. Le Guin',
         'first_sentence': 'With a clamor of bells that set the swallows soaring, the Festival of Summer came to the city Omelas, bright-towered by the sea.',
         'published': '1973'},
        {'id': 2,
         'title': 'Dhalgren',
         'author': 'Samuel R. Delany',
         'first_sentence': 'to wound the autumnal city.',
         'published': '1975'}
    ]

    #Создание точки доступа для API
    @app.route('/', methods=['GET'])
    def home():
        return '''<h1>Books API</h1>
    <p>A prototype API for retrieving books.</p>'''

    #Создание точки доступа для всех книг
    @app.route('/api/v1/resources/books/all', methods=['GET'])
    def api_all():
        return jsonify(books)

    #Создание точки доступа для одной книги
    @app.route('/api/v1/resources/books', methods=['GET'])
    def api_id():
        #проверьте, был ли указан идентификатор как часть URL-адреса
        #если указан идентификатор, присвойте его переменной
        #если идентификатор не указан, вывести ошибку
        if 'id' in request.args:
            id = int(request.args['id'])
        else:
            return "Error: No id field provided. Please specify an id."

        #создаем пустой список для наших результатов
        results = []

        #проходим по данным и сопоставляем результаты, соответствующие запрошенному идентификатору
        #ID уникальны, но другие поля могут возвращать много результатов
        for book in books:
            if book['id'] == id:
                results.append(book)

        #используем функцию jsonify из Flask, чтобы преобразовать наш список
        #Словари Python в формат JSON
        return jsonify(results)

    app.run()
    ```

> Так является ли разнообразие выходных данных проблемой?

Зависит от того, что вы пытаетесь сделать. Если вы хотите конкретного ответа, то это проблема. Если вас устраивает разнообразный результат, например «Составьте любые 3 вопроса по географии», то это не проблема.

### Использование температуры для вариативности вывода

Итак, мы решили, что хотим ограничить вывод, чтобы он был более предсказуемым, то есть более детерминированным. Как мы это сделаем?

Температура — это значение от 0 до 1, где 0 — наиболее детерминированный, а 1 — наиболее изменчивый. Значение по умолчанию — 0,7. Давайте посмотрим, что произойдет при двух запусках одного и того же приглашения с температурой, установленной на 0,1:

> "Создай код для веб-API Python."

    ```python
    #import necessary libraries
    import flask
    from flask import request, jsonify

    #create an instance of the Flask class
    app = flask.Flask(__name__)

    #create an endpoint for the API
    @app.route('/api/v1/endpoint', methods=['GET'])
    def api_endpoint():
        #get the request data
        data = request.get_json()

        #process the data
        result = process_data(data)

        #return the result
        return jsonify(result)

    #function to process the data
    def process_data(data):
        #process the data
        result = {'result': 'success'}

        #return the result
        return result

    #run the Flask app
    if __name__ == '__main__':
        app.run()

    ```

Повторный запуск дает нам такой результат:

    ```python
    #import necessary libraries
    import flask
    from flask import request, jsonify

    #create a Flask app
    app = flask.Flask(__name__)

    #create a route for the API
    @app.route('/api', methods=['GET'])
    def api_call():
        #get the data from the request
        data = request.get_json()

        #process the data
        result = process_data(data)

        #return the result
        return jsonify(result)

    #define the process_data function
    def process_data(data):
        #do something with the data
        result = data + 1

        #return the result
        return result

    #run the app
    if __name__ == '__main__':
        app.run()

    ```

Между этими двумя выводами есть лишь небольшая разница. Давайте на этот раз сделаем наоборот, установим температуру 0,9:

    ```python
    # Import necessary libraries
    import flask
    from flask import request, jsonify

    # Create a Flask app
    app = flask.Flask(__name__)

    # Create a route for the API
    @app.route('/api', methods=['GET'])
    def api_call():
        # Get the data from the request
        data = request.args

        # Process the data
        result = process_data(data)

        # Return the result
        return jsonify(result)

    # Function to process the data
    def process_data(data):
        # Do something with the data
        result = data + 1

        # Return the result
        return result

    # Run the app
    if __name__ == '__main__':
        app.run()

    ```

and the second attempt at 0.9 as temperature value:

    ```python
    import flask
    from flask import request, jsonify

    # create the Flask app
    app = flask.Flask(__name__)
    app.config['DEBUG'] = True

    # create some test data
    books = [
        {'id': 0, 'title': 'A Fire Upon The Deep', 'author': 'Vernor Vinge', 'first_sentence': 'The coldsleep itself was dreamless.', 'year_published': '1992'},
        {'id': 1, 'title': 'The Ones Who Walk Away From Omelas', 'author': 'Ursula K. Le Guin', 'first_sentence': 'With a clamor of bells that set the swallows soaring, the Festival of Summer came to the city Omelas, bright-towered by the sea.', 'published': '1973'},
        {'id': 2, 'title': 'Dhalgren', 'author': 'Samuel R. Delany', 'first_sentence': 'to wound the autumnal city.', 'published': '1975'}
    ]

    # create an endpoint
    @app.route('/', methods=['GET'])
    def home():
        return '''<h1>Welcome to our book API!</h1>'''

    @app.route('/api/v1/resources/books

    ```

Как видите, результаты очень разнятся.

> Note, that there are more parameters you can change to vary the output, like top-k, top-p, repetition penalty, length penalty and diversity penalty but these are outside the scope of this curriculum.

## Передовая практика

Существует множество практик, которые вы можете применить, чтобы попытаться получить то, что хотите. Вы найдете свой собственный стиль по мере того, как будете все чаще и чаще использовать подсказки.

Кроме техник, о которых мы уже говорили, есть несколько хороших практик, которые стоит учесть при использовании подсказок с помощью языковой модели.

Вот несколько хороших практик, которые стоит рассмотреть:

- **Уточните контекст**. Контекст имеет значение, и чем более подробно вы можете указать домен, тему и т.д., тем лучше.
- **Ограничьте вывод**. Если вам нужно определенное количество элементов или определенная длина, укажите это.
- **Укажите и что, и как**. Помните упоминать как то, что вы хотите, так и как вы хотите это получить. Например: "Создайте веб-API на Python с маршрутами 'products' и 'customers', разделите его на 3 файла".
- **Используйте шаблоны**. Часто вам захочется обогатить свои подсказки данными из вашей компании. Для этого используйте шаблоны. Шаблоны могут содержать переменные, которые вы заменяете на актуальные данные.
- **Правильно пишите слова**. Языковые модели могут предоставить вам правильный ответ, но если вы правильно пишете слова, вы получите более точный ответ.

## Присвоение

Вот код на Python, показывающий, как создать простой API с помощью Flask:

    ```python
    from flask import Flask, request

    app = Flask(__name__)

    @app.route('/')
    def hello():
        name = request.args.get('name', 'World')
        return f'Hello, {name}!'

    if __name__ == '__main__':
        app.run()
    ```

Используйте помощника на основе искусственного интеллекта, такого как GitHub Copilot или ChatGPT, и примените метод "самосовершенствования" для улучшения кода.

## Решение

Пожалуйста, попробуйте решить задание, добавляя подходящие подсказки к коду.

> [!СОВЕТ]
> Сформулируйте подсказку, чтобы попросить улучшить код. Хорошей идеей будет ограничить количество улучшений. Вы также можете попросить улучшить его в определенном аспекте, например, архитектуре, производительности, безопасности и т.д.

[Решение](./python/aoai-solution.py?WT.mc_id=academic-105485-koreyst)

## Проверка знаний

Why would I use chain-of-thought prompting? Show me 1 correct response and 2 incorrect responses.

1. Научить LLM решать проблемы.
2. Научить LLM находить ошибки в коде.
3. Поручить LLM предложить различные решения.

Ответ: 1, потому что цепочка мыслей подходит для того, чтобы показать LLM, как решить проблему, предоставив ей ряд шагов, а также похожие проблемы и способы их решения.

## 🚀 Испытание

Вы только что использовали метод самосовершенствования в задании. Возьмите любую программу, которую вы создали, и подумайте, какие улучшения вы бы хотели внести в нее. Теперь используйте метод самосовершенствования, чтобы применить предлагаемые изменения. Что вы думаете о результате? Лучше или хуже?

## Отличная работа! Продолжайте обучение

После завершения этого урока ознакомьтесь с нашей [коллекцией для изучения Generative AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), чтобы продолжить совершенствовать свои знания о генеративном искусственном интеллекте!

Переходите к уроку 6, где мы применим наши знания в области проектирования подсказок. [создание приложений для генерации текста](../06-text-generation-apps/README.md?WT.mc_id=academic-105485-koreyst)
