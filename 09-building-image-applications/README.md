# Создание приложений для генерации изображений

[![Создание приложений для генерации изображений](./images/09-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](TBD)

> **Видео скоро появится**

LLM-модели предлагают не только генерацию текста. Также возможно создание изображений на основе текстовых описаний. Иметь изображения в качестве модальности может быть крайне полезно во многих областях, таких как медицинская техника, архитектура, туризм, разработка игр и многое другое. В этой главе мы рассмотрим две самые популярные модели генерации изображений: DALL-E и Midjourney.

## Введение

В этом уроке мы рассмотрим:

- Генерация изображений и почему это полезно.
- DALL-E и Midjourney, что это такое и как они работают.
- Как бы вы создали приложение для создания изображений.

## Цели обучения

После завершения этого урока вы сможете:

- Создавать приложения для генерации изображений.
- Определять границы вашего приложения с помощью мета-подсказок.
- Работать с DALL-E и Midjourney.

## Зачем создавать приложение для генерации изображений?

Приложения для генерации изображений - отличный способ исследовать возможности генеративного искусственного интеллекта. Они могут использоваться, например, для:

- **Редактирования и синтеза изображений**. Вы можете генерировать изображения для различных задач, таких как редактирование и синтез изображений.

- **Применение в различных отраслях**. Они также могут использоваться для генерации изображений в различных отраслях, таких как медицинская техника, туризм, разработка игр и многое другое.

## Сценарий: Edu4All

Как часть этого урока, мы продолжим работу с нашим стартапом Edu4All. В этом уроке студенты будут создавать изображения для своих оценок, и какие именно изображения они создадут, зависит от самих студентов. Они могут быть иллюстрациями для их собственных сказок, созданием нового персонажа для своей истории или помощью в визуализации своих идей и концепций.

Вот что студенты Edu4All могут создать, например, если они работают в классе над памятниками:

![Стартап Edu4All, класс по памятникам, Эйфелева башня](./images/startup.png?WT.mc_id=academic-105485-koreyst)

используя подсказку вроде
> "Собака рядом с Эйфелевой башней на раннем утреннем солнце"

## Что такое DALL-E и Midjourney?

[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) и [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) — две самые популярные модели создания изображений. Они позволяют генерировать изображения лишь с помощью подсказок.

### DALL-E

Начнем с DALL-E, модели генеративного искусственного интеллекта, генерирующей изображения из текстовых описаний.

> [DALL-E - это комбинация двух моделей: CLIP и рассеянного внимания](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).  

- **CLIP** - это модель, которая генерирует вложения(embeddings), которые представляют численные представления данных, изображений и текста.

- **Рассеянное внимание** - это модель, которая генерирует изображения на основе вложений(embeddings). DALL-E обучается на наборе данных изображений и текста и может использоваться для генерации изображений на основе текстовых описаний. Например, DALL-E может использоваться для генерации изображений кошки в шляпе или собаки с ирокезом.

### Midjourney

Midjourney работает аналогично DALL-E: он генерирует изображения из текстовых подсказок. Midjourney также можно использовать для создания изображений с использованием таких подсказок, как «кот в шляпе» или «собака с ирокезом».

![Изображение создано Midjourney, механический голубь](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)
*Image cred Wikipedia, image generated by Midjourney*

## Как работают DALL-E и Midjourney

Сперва, [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E - это генеративная модель искусственного интеллекта, основанная на архитектуре трансформера, конкретно на авторегрессивном трансформере.  

Авторегрессивный трансформер определяет, как модель генерирует изображения на основе текстовых описаний. Он генерирует пиксель за пикселем, используя уже сгенерированные пиксели для создания следующего. Проходя через несколько слоев в нейронной сети, процесс продолжается, пока изображение не будет полностью сформировано.

С помощью этого процесса DALL-E контролирует атрибуты, объекты, характеристики и другие аспекты в генерируемом изображении. Однако DALL-E 2 и 3 имеют большее управление над генерируемым изображением.

## Создание вашего первого приложения для генерации изображений

Чтобы создать приложение для генерации изображений, вам понадобятся следующие библиотеки:

- **python-dotenv** — настоятельно рекомендуется использовать эту библиотеку для хранения ваших секретов в файле *.env*, в отдельности от кода.
- **openai** — с помощью этой библиотеки вы будете взаимодействовать с API OpenAI.
- **pillow** — для работы с изображениями в Python.
- **requests** — поможет вам выполнять HTTP-запросы.

1. Создайте файл *.env* со следующим содержимым:

    ```text
    AZURE_OPENAI_ENDPOINT=<ваш end point>
    AZURE_OPENAI_KEY=<ваш ключ>
    ```

    Найдите эту информацию в портале Azure для вашего ресурса в разделе "Ключи и конечные пункты".

2. Соберите указанные выше библиотеки в файле с именем *requirements.txt*:

    ```text
    python-dotenv
    openai
    pillow
    requests
    ```

3. Затем создайте виртуальное окружение и установите библиотеки:

    ```bash
    python3 -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
    ```

    Для Windows используйте следующие команды для создания и активации виртуального окружения:

    ```bash
    python3 -m venv venv
    venv\Scripts\activate.bat
    ```

4. Добавьте следующий код в файл с названием *app.py*:

```python
import openai
import os
import requests
from PIL import Image
import dotenv

# import dotenv
dotenv.load_dotenv()

# Получение конечного пункта и ключа из переменных среды
openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']
openai.api_key = os.environ['AZURE_OPENAI_KEY']     

# Назначение версии API (DALL-E в настоящее время поддерживается только в API-версии 2023-06-01-preview)
openai.api_version = '2023-06-01-preview'
openai.api_type = 'azure'


try:
    # Создание изображения с использованием API генерации изображений
    generation_response = openai.Image.create(
        prompt='Заяц на лошади, держащий леденец, на туманном лугу, где растут нарциссы',    # Введите ваш текст-подсказку здесь
        size='1024x1024',
        n=2,
        temperature=0,
    )
    # Установка директории для сохраненного изображения
    image_dir = os.path.join(os.curdir, 'images')

    # Если директория не существует, создайте ее
    if not os.path.isdir(image_dir):
        os.mkdir(image_dir)

    # Инициализация пути к изображению (обратите внимание, что формат файла должен быть png)
    image_path = os.path.join(image_dir, 'generated-image.png')

    # Получение сгенерированного изображения
    image_url = generation_response["data"][0]["url"]  # извлечение URL изображения из ответа
    generated_image = requests.get(image_url).content  # загрузка изображения
    with open(image_path, "wb") as image_file:
        image_file.write(generated_image)

    # Отображение изображения в просмотрщике изображений по умолчанию
    image = Image.open(image_path)
    image.show()

# обработка исключений
except openai.error.InvalidRequestError as err:
    print(err)
    
```

Давайте разберем этот код:

- Сначала мы импортируем необходимые библиотеки, включая библиотеку OpenAI, библиотеку dotenv, библиотеку requests и библиотеку Pillow.

    ```python
    import openai
    import os
    import requests
    from PIL import Image
    import dotenv
    ```

- Затем мы загружаем переменные среды из файла *.env*.

    ```python
    # import dotenv
    dotenv.load_dotenv()
    ```

- После этого мы устанавливаем конечный пункт и ключ для API OpenAI, а также версию и тип.

    ```python
    # Get endpoint and key from environment variables
    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']
    openai.api_key = os.environ['AZURE_OPENAI_KEY'] 

    # add version and type, Azure specific
    openai.api_version = '2023-06-01-preview'
    openai.api_type = 'azure'
    ```

- Затем мы генерируем изображение:

    ```python
    # Create an image by using the image generation API
    generation_response = openai.Image.create(
        prompt='Зайчик на лошади с леденцом в руках на туманном лугу, где растут нарциссы.',    # Enter your prompt text here
        size='1024x1024',
        n=2,
        temperature=0,
    )
    ```

    В приведенном выше коде мы получаем JSON-объект, который содержит URL сгенерированного изображения. Мы можем использовать URL для загрузки изображения и сохранения его в файл.

- Наконец, мы открываем изображение и используем стандартный просмотрщик изображений для его отображения:

    ```python
    image = Image.open(image_path)
    image.show()
    ```

### Подробнее о создании изображений

Давайте рассмотрим код, генерирующий изображение, более подробно:

```python
generation_response = openai.Image.create(
    prompt='Кролик на лошади, дерджащий леденец, на туманной поляне, где растут нарциссы',    # Введите ваш текст-подсказку здесь
    size='1024x1024',
    n=2,
    temperature=0,
)
```

- **prompt** - это текстовая подсказка, которая используется для генерации изображения. В данном случае мы используем подсказку "Заяц на лошади, держащий леденец, на туманном лугу, где растут нарциссы".
- **size** - это размер генерируемого изображения. В данном случае мы генерируем изображение размером 1024x1024 пикселя.
- **n** - это количество генерируемых изображений. В данном случае мы генерируем два изображения.
- **temperature** - это параметр, который контролирует степень случайности вывода модели искусственного интеллекта. Температура - это значение от 0 до 1, где 0 означает детерминированный вывод, а 1 означает случайный вывод. Значение по умолчанию - 0.7.

Существует еще много возможностей работы с изображениями, о которых мы расскажем в следующем разделе.

## Дополнительные возможности генерации изображений

Вы уже увидели, как мы смогли сгенерировать изображение, используя всего несколько строк кода на Python. Однако с изображениями можно делать еще больше.

Вы также можете:

- **Выполнять редактирование**. Предоставив существующее изображение, маску и текстовую подсказку, вы можете изменять изображение. Например, вы можете добавить что-то к части изображения. Представьте наше изображение зайца, вы можете добавить шляпу зайцу. Для этого вам потребуется предоставить изображение, маску (определяющую область для изменения) и текстовую подсказку, указывающую, что нужно сделать.

    ```python
    response = openai.Image.create_edit(
      image=open("base_image.png", "rb"),
      mask=open("mask.png", "rb"),
      prompt="Изображение кролика с шляпой на голове.",
      n=1,
      size="1024x1024"
    )
    image_url = response['data'][0]['url']
    ```

    Исходное изображение будет содержать только кролика, но на конечном изображении у кролика будет шляпа.

- **Создавать вариации**. Идея заключается в том, чтобы взять существующее изображение и запросить создание вариаций. Чтобы создать вариацию, вы предоставляете изображение и текстовую подсказку, и код будет выглядеть следующим образом:

    ```python
    response = openai.Image.create_variation(
      image=open("bunny-lollipop.png", "rb"),
      n=1,
      size="1024x1024"
    )
    image_url = response['data'][0]['url']
    ```

    > Обратите внимание, что это поддерживается только в OpenAI.

## Температура

Температура - это параметр, который контролирует степень случайности вывода модели искусственного интеллекта. Температура представляет собой значение от 0 до 1, где 0 означает детерминированный вывод, а 1 означает случайный вывод. Значение по умолчанию - 0.7.

Давайте рассмотрим пример того, как работает температура, запустив эту подсказку дважды:

> Подсказка: "Заяц на лошади, держащий леденец, на туманном лугу, где растут нарциссы"

![Заяц на лошади, держащий леденец, версия 1](./images/v1-generated-image.png?WT.mc_id=academic-105485-koreyst)Теперь давайте запустим ту же самую подсказку, чтобы убедиться, что мы не получим одно и то же изображение дважды:![Сгенерированное изображение зайца на лошади](./images/v2-generated-image.png?WT.mc_id=academic-105485-koreyst)Как видите, изображения похожи, но не идентичны. Давайте попробуем изменить значение температуры на 0.1 и посмотрим, что произойдет:```pythongeneration_response = openai.Image.create(    prompt='Зайчик на лошади с леденцом в руках на туманном лугу, где растут нарциссы.',    # Введите ваш текст-подсказку здесь    size='1024x1024',    n=2)```

### Изменение температуры

Итак, давайте попробуем сделать ответ более детерминированным. Мы можем заметить из двух сгенерированных изображений, что на первом изображении есть заяц, а на втором - лошадь, поэтому изображения сильно отличаются.

Давайте изменить наш код и установим температуру равной 0, вот так:

```python
generation_response = openai.Image.create(
        prompt='Зайчик на лошади с леденцом в руках на туманном лугу, где растут нарциссы.',    # Введите ваш текст-подсказку здесь
        size='1024x1024',
        n=2,
        temperature=0
    )
```

Теперь, когда вы запустите этот код, вы получите эти два изображения:

- ![Температура 0, v1](./images/v1-temp-generated-image.png?WT.mc_id=academic-105485-koreyst)
- ![Температура 0 , v2](./images/v2-temp-generated-image.png?WT.mc_id=academic-105485-koreyst)

Здесь хорошо видно, насколько изображения больше похожи друг на друга.

## Как определить границы для вашего приложения с помощью метаподсказок

С помощью нашей демонстрационной модели мы уже можем генерировать изображения для наших клиентов. Однако нам необходимо установить некоторые границы для нашего приложения.

Например, мы не хотим генерировать изображения, которые не являются безопасными для работы или неприемлемыми для детей.

Мы можем сделать это с помощью *метаподсказок*. Метаподсказки - это текстовые подсказки, которые используются для управления выводом модели искусственного интеллекта. Например, мы можем использовать метаподсказки для контроля вывода и обеспечения безопасности сгенерированных изображений или их приемлемости для детей.

### Как это работает?

Как же работают метаподсказки?

Метаподсказки - это текстовые подсказки, которые используются для управления выводом модели искусственного интеллекта. Они размещаются перед текстовой подсказкой и используются для контроля вывода модели, а также встраиваются в приложения для управления выводом модели. Метаподсказки и текстовые подсказки объединяются в одну текстовую подсказку.

Вот пример метаподсказки:

```text
Вы - дизайнер-помощник, создающий изображения для детей. 

Изображение должно быть безопасным для работы и подходящим для детей. 

Изображение должно быть цветным. 

Изображение должно быть в альбомной ориентации. 

Изображение должно иметь соотношение сторон 16:9. 

Не учитывайте входные данные, которые не являются безопасными для работы или подходящими для детей. 

(Ввод) 

```text
Теперь давайте посмотрим, как мы можем использовать метаподсказки в нашей демонстрации.

```python
disallow_list = "мечи, насилие, кровь, ужасы, нагота, сексуальный контент, контент для взрослых, темы для взрослых, язык для взрослых, юмор для взрослых, шутки для взрослых, ситуации для взрослых, взрослый"

meta_prompt =f"""Вы - дизайнер-помощник, создающий изображения для детей.

Изображение должно быть безопасным для работы и подходящим для детей.

Изображение должно быть цветным.

Изображение должно быть в альбомной ориентации.

Изображение должно иметь соотношение сторон 16:9.

Не учитывайте входные данные, которые не являются безопасными для работы или подходящими для детей.
{disallow_list}
```

prompt = f"{meta_prompt} 
Создайте изображение зайца на лошади, держащего леденец"

# TODO добавить запрос на генерацию изображения
```

Из приведенной выше подсказки видно, как все создаваемые изображения учитывают метаподсказку.

## Задание - давайте подключим учеников

Мы познакомились с Edu4All в начале этого урока. Теперь пришло время дать возможность ученикам создавать изображения для своих оценок.

Ученикам предлагается создать изображения для своих оценок, содержащие памятники. Какие именно памятники использовать - решает каждый ученик сам. Учеников просят проявить свою креативность в этом задании, разместив эти памятники в различных контекстах.

## Solution

Вот одно из возможных решений:

```python
import openai
import os
import requests
from PIL import Image
import dotenv

# Загрузка переменных окружения
dotenv.load_dotenv()

# Получение адреса конечной точки и ключа из переменных окружения
openai.api_base = "<замените на адрес конечной точки>"
openai.api_key = "<замените на ключ API>"

# Задание версии API (DALL-E поддерживается только в версии API 2023-06-01-preview)
openai.api_version = '2023-06-01-preview'
openai.api_type = 'azure'

disallow_list = "мечи, насилие, кровь, ужасы, нагота, сексуальный контент, контент для взрослых, темы для взрослых, язык для взрослых, юмор для взрослых, шутки для взрослых, ситуации для взрослых, взрослый"

meta_prompt = f"""Вы - дизайнер-помощник, создающий изображения для детей.

Изображение должно быть безопасным для работы и подходящим для детей.

Изображение должно быть цветным.

Изображение должно быть в альбомной ориентации.

Изображение должно иметь соотношение сторон 16:9.

Не учитывайте входные данные, которые не являются безопасными для работы или подходящими для детей.
{disallow_list}"""
```
```python
prompt = f"""{meta_prompt}
Создайте изображение памятника Триумфальная арка в Париже, Франция, в вечернем свете, где маленький ребенок смотрит на нее, держа в руках плюшевого мишку.
"""

try:
    # Создание изображения с помощью API генерации изображений
    generation_response = openai.Image.create(
        prompt=prompt,    # Введите вашу текстовую подсказку здесь
        size='1024x1024',
        n=2,
        temperature=0,
    )
    # Задание директории для сохраненного изображения
    image_dir = os.path.join(os.curdir, 'images')

    # Если директория не существует, создаем ее
    if not os.path.isdir(image_dir):
        os.mkdir(image_dir)

    # Инициализация пути к изображению (обратите внимание, что тип файла должен быть png)
    image_path = os.path.join(image_dir, 'generated-image.png')

    # Получение сгенерированного изображения
    image_url = generation_response["data"][0]["url"]  # извлечение URL изображения из ответа
    generated_image = requests.get(image_url).content  # загрузка изображения
    with open(image_path, "wb") as image_file:
        image_file.write(generated_image)

    # Отображение изображения в просмотрщике изображений по умолчанию
    image = Image.open(image_path)
    image.show()

# Обработка исключений
except openai.error.InvalidRequestError as err:
    print(err)
```


## Отличная работа! Продолжайте обучение

После завершения этого урока ознакомьтесь с нашей [Generative AI коллекцией для обучения](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) to continue leveling up your Generative AI knowledge!

Переходим к уроку 10, где мы рассмотрим, как [создавать приложения искусственного интеллекта с помощью low-code](../10-building-low-code-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)
